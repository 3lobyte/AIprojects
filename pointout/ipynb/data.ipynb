{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POINTOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T07:29:09.276433Z",
     "start_time": "2019-06-07T07:29:09.263654Z"
    }
   },
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "The first thing we have to do is go to [POINTOUT](https://targetdetection.com) and download a dataset. In the example below, I download the airplanes dataset in Barcelona's airport.\n",
    "\n",
    "![gif](https://res.cloudinary.com/dwhsm5imq/image/upload/v1559811423/download_kg0sim.gif)\n",
    "\n",
    "You can download different datasets on different areas of interest (even in the entire world !). Also, if you are interested in some dataset that does not exist or has a small ammount of annotations you can create a new one and start adding annotations.\n",
    "\n",
    "Once you download the dataset, you have to copy the *dataset.zip* file alongside this notebook. Also, we need the *utils.py* file. If you are in colab you can get it with the following command. Also, make sure to select the runtime to GPU to share the data with the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T08:21:49.085606Z",
     "start_time": "2019-06-14T08:21:48.160088Z"
    }
   },
   "outputs": [],
   "source": [
    "# download utils.py (useful in colab)\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/juansensio/pointout/master/ipynb/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:00.750682Z",
     "start_time": "2019-06-13T10:28:00.201822Z"
    }
   },
   "outputs": [],
   "source": [
    "# If everything is correct, you should see the file dataset.zip and utils.py here\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "In this section we are going to explore the dataset and transform it to use it later for training of our model.\n",
    "\n",
    "First, unzip the folder and explore the images and annotations file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:01.465628Z",
     "start_time": "2019-06-13T10:28:00.767855Z"
    }
   },
   "outputs": [],
   "source": [
    "# unzip dataset to a folder called dataset\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PATH = 'dataset'\n",
    "\n",
    "if os.path.isdir(PATH):\n",
    "    shutil.rmtree(PATH)\n",
    "\n",
    "!unzip dataset.zip -d {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:01.998844Z",
     "start_time": "2019-06-13T10:28:01.468062Z"
    }
   },
   "outputs": [],
   "source": [
    "# list files in dataset\n",
    "\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:02.007473Z",
     "start_time": "2019-06-13T10:28:02.001566Z"
    }
   },
   "outputs": [],
   "source": [
    "# get images\n",
    "\n",
    "images = [file for file in os.listdir(PATH) if file[-3:] == 'png']\n",
    "print('Number of images: ', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:03.594595Z",
     "start_time": "2019-06-13T10:28:02.009357Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "\n",
    "from utils import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = open_image(PATH + '/' + images[random.randint(0, len(images)-1)])\n",
    "plt.imshow(img)\n",
    "print(\"Image dimensions (h, w, c): \", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that images can be very different in size due to the collaborative nature of the platform (each user can make annotations in different sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:03.606781Z",
     "start_time": "2019-06-13T10:28:03.596575Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse annotations\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "annotations_file_name = '{}/annotations.json'.format(PATH)\n",
    "with open(annotations_file_name) as f:\n",
    "    annotations_file = json.load(f)\n",
    "    \n",
    "annotations_file[random.randint(0, len(annotations_file)-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotations file contains a list of all the images, and for each one it contains some information (the bounding box in map coordinates, the zoom level at which it was saved, ...) and a list of all the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:04.054441Z",
     "start_time": "2019-06-13T10:28:03.608954Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize images with annotations\n",
    "\n",
    "ix = random.randint(0, len(annotations_file)-1)\n",
    "item = annotations_file[ix]\n",
    "\n",
    "img_name = item[\"name\"]\n",
    "anns = item['annotations']\n",
    "mBB = item['mapBB']\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "img = open_image('{}/{}'.format(PATH,img_name))\n",
    "ax.set_title('{} {}'.format(img_name, img.shape))\n",
    "ax = show_image(img, ax=ax)\n",
    "for ann in anns:\n",
    "    bb = ann['bbox']\n",
    "    bb = ltlg2xywh(bb, mBB, img.shape[:2])\n",
    "    draw_rect(ax, bb, 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch generation\n",
    "\n",
    "In order to train our detector, we first generate patches from the original images. To that end we build a dataframe with the images and annotations. We save annotations in the COCO format (x, y, w, h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:04.677461Z",
     "start_time": "2019-06-13T10:28:04.056687Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "img_names, annotations = [], []\n",
    "for ann in annotations_file:\n",
    "    img_name = ann[\"name\"]\n",
    "    img_names.append(img_name)\n",
    "    img = open_image('{}/{}'.format(PATH,img_name))\n",
    "    anns = ann['annotations']\n",
    "    mBB = ann['mapBB']\n",
    "    _annotations = []\n",
    "    for _ann in anns:\n",
    "        bb = _ann['bbox']\n",
    "        # convert bb from (lat, lng) to (x, y, w, h)\n",
    "        bb = ltlg2xywh(bb, mBB, img.shape[:2])\n",
    "        bb = [int(b) for b in bb]\n",
    "        # save tuple (bb, label)\n",
    "        _annotations.append((bb, 0))\n",
    "    annotations.append(_annotations)\n",
    "        \n",
    "df = pd.DataFrame({'img_name': img_names, 'annotations': annotations})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split our dataset in training and validation images. During the training we will feed the network with batches of randomized patches from the trainig set. Then, we will use the patches in the validation set to evaluate the performance of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:04.758246Z",
     "start_time": "2019-06-13T10:28:04.680463Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_t, df_v = train_test_split(df, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "print(\"Training images: \", len(df_t))\n",
    "print(\"Validation images: \", len(df_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a window and a stride and generate patches from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:05.382694Z",
     "start_time": "2019-06-13T10:28:04.760656Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a window and a stride and create folder to save patches\n",
    "\n",
    "window, stride = 256, 100\n",
    "\n",
    "patches_folder = '{}/patches_{}_{}'.format(PATH, window, stride)\n",
    "if os.path.isdir(patches_folder):\n",
    "    shutil.rmtree(patches_folder)\n",
    "os.mkdir(patches_folder)\n",
    "\n",
    "!ls {PATH} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:28:54.051565Z",
     "start_time": "2019-06-13T10:28:05.384895Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate training patches\n",
    "\n",
    "dfa, dfm = build_patches(df_t, PATH, patches_folder, window, stride, perc=0.5)\n",
    "dfa.to_csv('{}/annotations_train.csv'.format(patches_folder), index=None)\n",
    "dfm.to_csv('{}/mosaics_train.csv'.format(patches_folder), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:29:20.998718Z",
     "start_time": "2019-06-13T10:28:54.053257Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate validations patches\n",
    "\n",
    "dfa, dfm = build_patches(df_v, PATH, patches_folder, window, stride, perc=0.5)\n",
    "dfa.to_csv('{}/annotations_eval.csv'.format(patches_folder), index=None)\n",
    "dfm.to_csv('{}/mosaics_eval.csv'.format(patches_folder), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load our patch-level annotations to check that everything is ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:29:21.025315Z",
     "start_time": "2019-06-13T10:29:21.000488Z"
    }
   },
   "outputs": [],
   "source": [
    "# load annotations and visualize patches\n",
    "\n",
    "df_t = pd.read_csv('{}/annotations_train.csv'.format(patches_folder))\n",
    "mosaics_t = pd.read_csv(\"{}/mosaics_train.csv\".format(patches_folder))\n",
    "\n",
    "df_v = pd.read_csv('{}/annotations_eval.csv'.format(patches_folder))\n",
    "mosaics_v = pd.read_csv(\"{}/mosaics_train.csv\".format(patches_folder))\n",
    "\n",
    "# convert string of bbs into list of bbs\n",
    "\n",
    "df_t.annotations = anns_str2int(df_t.annotations.values)\n",
    "mosaics_t.annotations = anns_str2int(mosaics_t.annotations.values)\n",
    "\n",
    "df_v.annotations = anns_str2int(df_v.annotations.values)\n",
    "mosaics_v.annotations = anns_str2int(mosaics_v.annotations.values)\n",
    "\n",
    "print(\"Training patches: \",len(df_t))\n",
    "print(\"Validation patches: \",len(df_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:29:21.032629Z",
     "start_time": "2019-06-13T10:29:21.026990Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose one dataset for visualization\n",
    "\n",
    "df = df_t\n",
    "mosaics = mosaics_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:29:21.596806Z",
     "start_time": "2019-06-13T10:29:21.034420Z"
    }
   },
   "outputs": [],
   "source": [
    "# show random patches\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10,10))\n",
    "for i, _ax in enumerate(axs):\n",
    "    for ix, ax in enumerate(_ax):\n",
    "        \n",
    "        ix = random.randint(0, len(df)-1)\n",
    "        img_name, anns = df.loc[ix].img_name, df.loc[ix].annotations\n",
    "        img = open_image('{}/{}'.format(patches_folder,img_name))\n",
    "        ax = show_image(img, ax=ax)\n",
    "        for bb, label in anns:\n",
    "            draw_rect(ax, bb, 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:29:24.539118Z",
     "start_time": "2019-06-13T10:29:21.598230Z"
    }
   },
   "outputs": [],
   "source": [
    "# show patches in random mosaic\n",
    "\n",
    "ix = random.randint(0, len(mosaics)-1)\n",
    "mosaic = mosaics.loc[ix]\n",
    "\n",
    "img_ori = open_image(\"{}/{}\".format(PATH, mosaic.img_name))\n",
    "anns_ori = mosaic.annotations\n",
    "mosaic = mosaic.mosaic\n",
    "mosaic = mosaic.split(',')[:-1]\n",
    "mosaic = [m.split(' ')[:-1] for m in mosaic]\n",
    "shape = (len(mosaic), len(mosaic[0]))\n",
    "\n",
    "fig, axs = plt.subplots(shape[0], shape[1], figsize=(20,20))\n",
    "for i, _ax in enumerate(axs):\n",
    "    for j, ax in enumerate(_ax):\n",
    "\n",
    "        ix = int(mosaic[i][j])\n",
    "        img_name, anns = df.loc[ix].img_name, df.loc[ix].annotations\n",
    "        img = open_image('{}/{}'.format(patches_folder,img_name))\n",
    "        ax = show_image(img, ax=ax)\n",
    "        for bb, label in anns:\n",
    "            draw_rect(ax, bb, 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T10:29:24.855361Z",
     "start_time": "2019-06-13T10:29:24.540690Z"
    }
   },
   "outputs": [],
   "source": [
    "# show original image\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = show_image(img_ori, ax=ax)\n",
    "for bb, label in anns_ori:\n",
    "    draw_rect(ax, bb, 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data in place, we can proceed to the training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
